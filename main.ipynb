{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "sys.path.insert(1, '/mnt/c/MBA/')\n",
    "from model_functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime,date, timedelta\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet  \n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import json\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/mnt/c/MBA'\n",
    "\n",
    "list_files = glob.glob(f'{root}/data2/*.parquet*') \n",
    "\n",
    "i= 0\n",
    "\n",
    "print(len(list_files))\n",
    "\n",
    "for file in list_files:\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    frame= pd.read_parquet(file, columns=['date_ref', 'WS100'])\n",
    "\n",
    "    df=frame[(frame.groupby('date_ref').cumcount()== 4)].reset_index(drop=True)\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df['date_ref'] = pd.to_datetime(df['date_ref'])\n",
    "\n",
    "df = df.drop(df.tail(11).index)\n",
    "\n",
    "df = df.sort_values('date_ref').reset_index(drop=True)\n",
    "\n",
    "df = df.set_index('date_ref').resample('MS').mean().reset_index()\n",
    "\n",
    "df = df.rename({'date_ref': 'ds', 'WS100': 'y'}, axis=1)\n",
    "\n",
    "df = df.set_index('ds').asfreq('MS')\n",
    "\n",
    "df =add_fourier_terms(df, 1)\n",
    "\n",
    "df.to_parquet(f'{root}/wind.parquet', engine='fastparquet')\n",
    "\n",
    "dataframe = pd.read_parquet(f'{root}/wind.parquet', engine='fastparquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "directory=os.path.join(root,'figures')\n",
    "    \n",
    "if not os.path.exists(directory):\n",
    "  os.makedirs(directory)\n",
    "\n",
    "directory=os.path.join(root,'models')\n",
    "    \n",
    "if not os.path.exists(directory):\n",
    "  os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "period = 12\n",
    "\n",
    "orders = {}\n",
    "\n",
    "auto_arima_dict = {'serie': None, 'start_p': 1, 'start_q': 1,\n",
    "            'start_P': 1, 'start_Q': 1, \n",
    "            'max_p': 2, 'max_q': 2,\n",
    "            'max_P': 5, 'max_Q': 5,\n",
    "            'max_d': 2, 'max_D': 1,\n",
    "            'max_order': None,  'd': None, 'D': None,\n",
    "            'test': \"adf\", 'm': 12,\n",
    "            'stepwise': True, 'trace': True,\n",
    "            'stationary': False, 'seasonal': True}\n",
    "\n",
    "\n",
    "serie = dataframe[['y']]\n",
    "\n",
    "trend_estimate_ad, periodic_estimate_ad, residual_ad = decomp(serie,period, root)\n",
    "\n",
    "check_stationarity_plots_acf_pacf(serie, trend_estimate_ad, periodic_estimate_ad, residual_ad, root)\n",
    "\n",
    "auto_arima_dict['serie'] = serie\n",
    "\n",
    "order = sarimax_diagnostic(auto_arima_dict, root)\n",
    "\n",
    "orders.update(order)\n",
    "\n",
    "dataframe = dataframe.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_string = json.dumps(orders)\n",
    "\n",
    "with open(f'{root}/json_data.json', 'w') as outfile:\n",
    "    outfile.write(json_string)\n",
    "\n",
    "with open(f'{root}/json_data.json') as json_file:\n",
    "    orders = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_optuna='optuna'\n",
    "\n",
    "tuning_results_all = pd.DataFrame()\n",
    "\n",
    "initial= 12 * 30\n",
    "period= 1 \n",
    "\n",
    "horizon_sarimax = 4\n",
    "horizon_prophet = f'{3 * 30 +10} days'\n",
    "\n",
    "run_cross_validation = True\n",
    "\n",
    "exog_cols=dataframe.reset_index(drop=True).drop(['ds', 'y'], axis=1).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_cross_validation==True:\n",
    "  \n",
    "    sarimax_cv_all = sarimax_crosvalidation(df=dataframe, order=orders['orders'][0], seasonal_order=orders['orders'][1], initial=initial, period=period, \n",
    "                                        horizon=horizon_sarimax, exog_col=exog_cols).sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "    m = Prophet(interval_width=0.95)\n",
    "    \n",
    "    if exog_cols != None:\n",
    "        for col in exog_cols:\n",
    "            m.add_regressor(col)   \n",
    "\n",
    "    m.fit(dataframe)\n",
    "\n",
    "    plots_prophet(m, sarimax_cv_all, prefix='Sarimax', root=root)\n",
    "\n",
    "    if os.path.isfile('models/Prophet_bst_params.json'):\n",
    "        with open(f'{root}/models/Prophet_bst_params.json', 'r') as x:\n",
    "            best_params = json.load(x)\n",
    "\n",
    "    elif grid_optuna == 'grid':          \n",
    "        best_params, tuning_results = grid_search_prophet(df=dataframe, initial=initial, period=period, horizon=horizon_prophet, param_grid={}, exog_col=exog_cols)\n",
    "        tuning_results_all = tuning_results_all.append(tuning_results)\n",
    "        with open(f'{root}/models/Prophet_bst_params.json', 'w') as x:\n",
    "            json.dump(best_params, x)\n",
    "\n",
    "    elif grid_optuna =='optuna':\n",
    "        best_params =optuna_prophet(df=dataframe, initial=initial, period=period, horizon=horizon_prophet)\n",
    "        with open(f'{root}/models/Prophet_bst_params.json', 'w') as x:\n",
    "            json.dump(best_params, x)\n",
    "    else:\n",
    "        best_params = {'changepoint_prior_scale': 0.1,\n",
    "            'seasonality_prior_scale': 0.1,\n",
    "            'seasonality_mode': 'multiplicative',\n",
    "            'weekly_seasonality':False,\n",
    "                }\n",
    "            \n",
    "    m = Prophet(**best_params, interval_width=0.95)\n",
    "\n",
    "    if exog_cols != None:\n",
    "        for col in exog_cols:\n",
    "            m.add_regressor(col)     \n",
    "\n",
    "    m.fit(dataframe)  \n",
    "\n",
    "    cutoffs = []\n",
    "    cutoff  = dataframe.ds.min()+relativedelta(months=initial)\n",
    "    while cutoff<dataframe.ds.max()-relativedelta(months=period*5):\n",
    "        cutoffs=cutoffs + [cutoff]\n",
    "        cutoff = cutoff+relativedelta(months=period)\n",
    "\n",
    "    prophet_cv_all = cross_validation(m, cutoffs=cutoffs, horizon=horizon_prophet).sort_values('ds').reset_index(drop=True)\n",
    "\n",
    "    with open(f'{root}/models/prophet_model', 'w') as fout:\n",
    "        fout.write(model_to_json(m))       \n",
    "    with open(f'{root}/models/prophet_model', 'r') as fin:\n",
    "        m = model_from_json(fin.read())\n",
    "\n",
    "    plots_prophet(m, prophet_cv_all, prefix='Prophet', root=root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_dates = pd.date_range(start=dataframe['ds'].max()+pd.offsets.MonthBegin(1), periods=3, freq='MS')\n",
    "\n",
    "# SARIMAX\n",
    "#--------\n",
    "if exog_cols != None:\n",
    "    model = SARIMAX(dataframe[['y']], order=orders['orders'][0], seasonal_order=orders['orders'][1], exog=dataframe[exog_cols],enforce_stationarity=False)\n",
    "\n",
    "else:\n",
    "    model = SARIMAX(dataframe[['y']], order=orders['orders'][0], seasonal_order=orders['orders'][1],enforce_stationarity=False)\n",
    "\n",
    "sarimax_model = model.fit(disp=0)\n",
    "\n",
    " \n",
    "sarimax_future = pd.DataFrame({'ds': future_dates})\n",
    "sarimax_future = sarimax_future.set_index('ds').asfreq('MS')\n",
    "sarimax_future = add_fourier_terms(sarimax_future, 1).reset_index()\n",
    "\n",
    "if exog_cols != None:\n",
    "\n",
    "    forecast = sarimax_model.get_forecast(steps=3, alpha=0.05, exog=sarimax_future[exog_cols])\n",
    "\n",
    "else:\n",
    "    \n",
    "    forecast = sarimax_model.get_forecast(steps=3, alpha=0.05)\n",
    "\n",
    "sarimax_future['yhat']       = forecast.predicted_mean.reset_index(drop=True)\n",
    "sarimax_future['yhat_upper'] = forecast.conf_int()['upper y'].reset_index(drop=True)\n",
    "sarimax_future['yhat_lower'] = forecast.conf_int()['lower y'].reset_index(drop=True)\n",
    "\n",
    "if exog_cols != None:\n",
    "\n",
    "    sarimax_future = sarimax_future[['ds', 'yhat', 'yhat_lower', 'yhat_upper']+ exog_cols]\n",
    "    \n",
    "else:\n",
    "    \n",
    "    sarimax_future = sarimax_future[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "sarimax_future = sarimax_future.dropna()\n",
    "\n",
    "sarimax_future['cutoff']  = dataframe['ds'].max()\n",
    "\n",
    "with open(f'{root}/models/Prophet_bst_params.json', 'r') as x:\n",
    "    best_params = json.load(x)\n",
    "\n",
    "m = Prophet(**best_params, interval_width=0.95)\n",
    "\n",
    "if exog_cols != None:\n",
    "    for col in exog_cols:\n",
    "        m.add_regressor(col)   \n",
    "\n",
    "m.fit(dataframe)  \n",
    "\n",
    "prophet_future = pd.DataFrame({'ds': future_dates})\n",
    "prophet_future = prophet_future.set_index('ds').asfreq('MS')\n",
    "prophet_future =add_fourier_terms(prophet_future, 1).reset_index()\n",
    "\n",
    "if exog_cols != None:\n",
    "\n",
    "    prophet_future = m.predict(prophet_future)[['ds','yhat', 'yhat_lower', 'yhat_upper']+exog_cols]\n",
    "\n",
    "else:\n",
    "    \n",
    "    prophet_future = m.predict(prophet_future)[['ds','yhat', 'yhat_lower', 'yhat_upper']]\n",
    "\n",
    "prophet_future['cutoff'] = dataframe['ds'].max()\n",
    "\n",
    "\n",
    "prophet_cv_all = pd.concat([prophet_cv_all,prophet_future], axis=0).reset_index(drop=True)\n",
    "sarimax_cv_all = pd.concat([sarimax_cv_all,sarimax_future], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_cv_all['month_sin'+str(1)] = prophet_cv_all.ds.apply(lambda x: np.sin(2 *1* np.pi * x.month/12)) \n",
    "prophet_cv_all['month_cos'+str(1)] = prophet_cv_all.ds.apply(lambda x:np.cos(2 *1* np.pi * x.month/12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_optuna=='grid':\n",
    "    tuning_results_all.to_excel('tuning_results.xlsx')\n",
    "\n",
    "prophet_cv_all['date_ref'] = prophet_cv_all.cutoff + pd.offsets.MonthBegin(1)\n",
    "sarimax_cv_all['date_ref'] = sarimax_cv_all.cutoff + pd.offsets.MonthBegin(1)\n",
    "\n",
    "prophet_cv_all.to_excel(f'{root}/Prophet_CrossValidation.xlsx')\n",
    "sarimax_cv_all.to_excel(f'{root}/Sarimax_CrossValidation.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_cv_all = pd.read_excel(f'{root}/Prophet_CrossValidation.xlsx', index_col=0)\n",
    "sarimax_cv_all = pd.read_excel(f'{root}/Sarimax_CrossValidation.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df  = prophet_cv_all.rename(columns={'ds':'date_forecast', 'yhat':'yhat_prophet'})\n",
    "\n",
    "\n",
    "if exog_cols != None:\n",
    "\n",
    "    if 'y' in df.columns:\n",
    "        df  = df[['date_ref', 'date_forecast', 'yhat_prophet', 'y']+exog_cols]\n",
    "    else:\n",
    "        df = df[['date_ref', 'date_forecast',  'yhat_prophet']+exog_cols]\n",
    "        df['y'] = np.nan\n",
    "\n",
    "else:\n",
    "\n",
    "    if 'y' in df.columns:\n",
    "        df  = df[['date_ref', 'date_forecast', 'yhat_prophet', 'y']]\n",
    "    else:\n",
    "        df = df[['date_ref', 'date_forecast',  'yhat_prophet']]\n",
    "        df['y'] = np.nan\n",
    "\n",
    "df2 = sarimax_cv_all.rename(columns={'ds':'date_forecast', 'yhat':'yhat_sarimax'})\n",
    "\n",
    "if exog_cols != None:\n",
    "\n",
    "    if 'y' in df2.columns:\n",
    "        df2  = df2[['date_ref', 'date_forecast', 'yhat_sarimax', 'y']+exog_cols]\n",
    "    else:\n",
    "        df2 = df2[['date_ref', 'date_forecast',  'yhat_sarimax']+exog_cols]\n",
    "        df2['y'] = np.nan\n",
    "\n",
    "else:\n",
    "\n",
    "    if 'y' in df2.columns:\n",
    "        df2  = df2[['date_ref', 'date_forecast', 'yhat_sarimax', 'y']]\n",
    "    else:\n",
    "        df2 = df2[['date_ref', 'date_forecast',  'yhat_sarimax']]\n",
    "        df2['y'] = np.nan\n",
    "\n",
    "df = df.merge(df2, how = 'left', on = ['date_ref', 'date_forecast', 'y']+exog_cols)\n",
    "\n",
    "df['delta'] = np.round(((df['date_forecast']-df['date_ref'])/np.timedelta64(1, 'M'))).astype(int)\n",
    "\n",
    "df['delta'] = df['delta']+1\n",
    "\n",
    "df = df.loc[(~df.yhat_prophet.isnull()) & (~df.yhat_sarimax.isnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['date_ref', 'date_forecast', 'delta', 'yhat_prophet', 'yhat_sarimax', 'y']+exog_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['yhat_prophet', 'yhat_sarimax']+exog_cols\n",
    "ohe_features = ['delta']\n",
    "\n",
    "df_reg = pd.DataFrame()\n",
    "\n",
    "date_refs = df.sort_values('date_ref').date_ref.unique()\n",
    "cutoffs = date_refs[round(len(date_refs)/2):]\n",
    "if run_cross_validation==True:   \n",
    "    for cutoff in cutoffs:\n",
    "        df_reg = df_reg.append(train_pred(df, cutoff, features, ohe_features))\n",
    "else:\n",
    "    for cutoff in cutoffs[-4:]:\n",
    "        df_reg = df_reg.append(train_pred(df, cutoff, features, ohe_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg[['date_ref', 'date_forecast', 'delta', 'yhat_prophet', 'yhat_sarimax',  'yhat_rf', 'yhat_lr', 'yhat_ls', 'yhat_dt', 'yhat_gbr', 'yhat_ada', 'y']+exog_cols]  \n",
    "\n",
    "print(\"Delete Values with date_ref that are being included:\")\n",
    "date_refs = [str(x)[0:10] for x in df_reg.date_ref.unique()]\n",
    "date_refs_str = str(date_refs).replace('[', '(').replace(']', ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if run_cross_validation==True:\n",
    "    df_reg = df_reg.dropna()\n",
    "    metricas = df_reg.groupby(['delta']).apply(metrics).reset_index()\n",
    "    metricas.to_excel('metrica.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "fig= plt.figure(figsize=(8, 6))\n",
    "plt.grid(False)\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "#plt.title(\"RMSE by Day\")\n",
    "plt.plot(metricas.delta, metricas.rmse, color='darkred',label='Prophet')\n",
    "plt.plot(metricas.delta, metricas.rmse_sarimax, color='orange',label='Sarimax')\n",
    "plt.plot(metricas.delta, metricas.rmse_lr, color='lime', label='LinearRegression')\n",
    "plt.plot(metricas.delta, metricas.rmse_rf, color='dodgerblue', label='RandomForestRegressor')\n",
    "plt.plot(metricas.delta, metricas.rmse_ls, color='blue', label='Lasso')\n",
    "plt.plot(metricas.delta, metricas.rmse_dt, color='darkviolet', label='DecisionTreeRegressor')\n",
    "plt.plot(metricas.delta, metricas.rmse_gbr, color='gray', label='GradientBoostingRegressor')\n",
    "plt.plot(metricas.delta, metricas.rmse_ada, color='black', label='AdaBoostRegressor')\n",
    "plt.legend(loc='lower left', bbox_to_anchor=(-0.05, -0.30), ncol=3)\n",
    "plt.xlabel('Meses à frente')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xticks([x for x in np.arange(1,4)], [str(x) for x in np.arange(1,4)])\n",
    "fig.savefig(f'{root}/figures/RMSE_by_month.png', bbox_inches='tight')    \n",
    "plt.show()\n",
    "#------\n",
    "fig= plt.figure(figsize=(8, 6))\n",
    "plt.grid(False)\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "#plt.title(\"MAPE por Delta\")\n",
    "\n",
    "plt.plot(metricas.delta, metricas.mape, color='darkred',label='Prophet')\n",
    "plt.plot(metricas.delta, metricas.mape_sarimax, color='orange',label='Sarimax')\n",
    "plt.plot(metricas.delta, metricas.mape_lr, color='lime', label='LinearRegression')\n",
    "plt.plot(metricas.delta, metricas.mape_rf, color='dodgerblue', label='RandomForestRegressor')\n",
    "plt.plot(metricas.delta, metricas.mape_ls, color='blue', label='Lasso')\n",
    "plt.plot(metricas.delta, metricas.mape_dt, color='darkviolet', label='DecisionTreeRegressor')\n",
    "plt.plot(metricas.delta, metricas.mape_gbr, color='gray', label='GradientBoostingRegressor')\n",
    "plt.plot(metricas.delta, metricas.mape_ada, color='black', label='AdaBoostRegressor')\n",
    "plt.legend(loc='lower left', bbox_to_anchor=(-0.05, -0.30), ncol=3)\n",
    "plt.xlabel('Meses à frente')\n",
    "plt.ylabel('MAPE')\n",
    "plt.xticks([x for x in np.arange(1,4)], [str(x) for x in np.arange(1,4)])\n",
    "fig.savefig(f'{root}/figures/MAPE_by_month.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "#------\n",
    "fig= plt.figure(figsize=(8, 6))\n",
    "plt.grid(False)\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "#plt.title(\"R² by Day - {}\")\n",
    "\n",
    "plt.plot(metricas.delta, metricas.r2, color='darkred',label='Prophet')\n",
    "plt.plot(metricas.delta, metricas.r2_sarimax, color='orange',label='Sarimax')\n",
    "plt.plot(metricas.delta, metricas.r2_rf, color='dodgerblue', label='RandomForestRegressor')\n",
    "plt.plot(metricas.delta, metricas.r2_lr, color='lime', label='LinearRegression')\n",
    "plt.plot(metricas.delta, metricas.r2_ls, color='blue', label='Lasso')\n",
    "plt.plot(metricas.delta, metricas.r2_dt, color='darkviolet', label='DecisionTreeRegressor')\n",
    "plt.plot(metricas.delta, metricas.r2_gbr, color='gray', label='GradientBoostingRegressor')\n",
    "plt.plot(metricas.delta, metricas.r2_ada, color='black', label='AdaBoostRegressor')\n",
    "plt.legend(loc='lower left', bbox_to_anchor=(-0.05, -0.30), ncol=3)\n",
    "plt.xlabel('Meses à frente')\n",
    "plt.ylabel('R²')\n",
    "plt.xticks([x for x in np.arange(1,4)], [str(x) for x in np.arange(1,4)])\n",
    "fig.savefig(f'{root}/figures/R2_by_month.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['axes.linewidth'] = 1.5\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "print('Correlations')\n",
    "print(df_reg[['yhat_prophet', 'yhat_sarimax',   'yhat_lr', 'yhat_rf','yhat_ls', 'yhat_dt', 'yhat_gbr', 'yhat_ada', 'y']].corr()['y'])\n",
    "plots= df_reg[['yhat_prophet', 'yhat_sarimax',   'yhat_lr', 'yhat_rf','yhat_ls', 'yhat_dt', 'yhat_gbr', 'yhat_ada', 'y']].corr(method='pearson').abs().plot.bar(y='y', color=['darkred','orange','dodgerblue',\n",
    "                                                                                                                                                                'lime','blue','darkviolet','gray',\n",
    "                                                                                                                                                                  'black', 'yellow'])\n",
    "for bar in plots.patches:\n",
    "\n",
    "    plots.annotate(format(bar.get_height(), '.2f'),\n",
    "                   (bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                   size=8, xytext=(0, 8),\n",
    "                   textcoords='offset points')\n",
    "\n",
    "plt.grid(False)\n",
    "plt.gca().spines[['right', 'top']].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{root}/figures/corr_complete.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7e0588f63f8c30afaa5d1524901f275d9b059757a0f3792d92a3b8d8d8d7f63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
